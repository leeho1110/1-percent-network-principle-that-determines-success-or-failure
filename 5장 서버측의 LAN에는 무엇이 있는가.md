# 5장: 서버측의 LAN에는 무엇이 있는가?

### 1. 웹 서버의 설치 장소

- 우리가 요청을 보내는 서버는 과연 어떻게 설치되어 있을까요?
    - 먼저 간단하게는 라우터와 사내 LAN이 프로바이더의 네트워크로부터 액세스 회선을 통해 직접 연결될 수 있습니다.
        - 하지만 IP 주소 부족과 보안 문제로 인해 현재는 위 방법은 사용되지 않는 경우가 많습니다.
    - 따라서 최근엔 액세스 회선과 사내 LAN 사이에 방화벽을 두는 경우가 일반적입니다.
        - 방화벽은 패킷들을 검증하여 통과시키거나 차단하는 역할을 수행합니다.

---

### 2. 방화벽의 원리와 동작

- 방화벽은 기본적으로 특정 서버와 서버 내 특정 애플리케이션에 액세스하는 패킷은 통과시키고 나머지는 차단하는 방법을 사용합니다.
    - 네트워크 상에선 다양한 패킷이 흐르기 때문에 이를 구별해내는 것은 쉬운 일이 아닙니다. 이런 방법 중 **패킷 필터링형**이 가장 일반적입니다.
- 패킷 필터링에서는 아래와 같은 정보들을 통해 부정 패킷을 판단합니다.
    - 가장 먼저 수신처와 송신처 IP 주소를 통해 시작점과 끝점을 판단합니다.
    - 그 다음은 특정 애플리케이션에 대한 접근을 위해 포트 번호를 추가로 적용합니다.
    - TCP 커넥션을 위한 3way 핸드쉐이킹에서 매겨지는 컨트롤 비트도 활용합니다.
- 방화벽은 패킷을 판정하며 버린 패킷에 대한 기록을 남깁니다.
    - 버린 패킷을 통해 부정 침입의 흔적을 확인해 대책을 마련하기 위함입니다.
- 패킷 필터링만으론 패킷 내의 위험한 데이터 문제는 검증해내지 못합니다.

---

### 3. 복수 서버에 리퀘스트를 분배한 서버의 부하 분산

- 서버에 트래픽이 늘어날 때 서버의 성능을 증가시키는 것말고도 다른 방법이 존재합니다. 이 중 하나가 서버의 대수를 늘려 할당되는 요청의 처리를 나누어 처리하는 **분산 처리**입니다.
    - 가장 간단한 방법은 DNS 레벨에서 나누는 것입니다. DNS 서버에 같은 이름으로 여러 웹 서버의 IP를 등록하면 DNS 서버는 요청마다 **차례대로 IP 주소를 반환하는 라운드 로빈 방식으로 요청을 분배**합니다.
    - 하지만 이 방법은 서버의 페일 오버가 발생하더라도 해당 서버의 주소를 반환하기 때문에 온전한 고가용성을 보장하기 어렵습니다.
- 이를 보완하기 위해 등장한 방식이 바로 **로드 밸런서(Load balancer)** 입니다.
    - 이 방법에선 DNS 서버에 서버의 주소를 등록하지 않고 로드 밸런서의 주소를 등록하고, 이를 통해 요청이 분배되도록 합니다.

---

### 4. 캐시 서버를 이용한 서버의 부하 분산

- 로드 밸런서가 아닌 **캐시 서버**로도 부하 분산이 가능합니다.
    - 캐시 서버는 응답 데이터를 미리 저장해두고 요청이 오는 경우, 미리 저장된 데이터를 반환합니다.
    - 만약 웹 서버에 데이터를 요청할 때 캐시 서버를 경유했다면 `Via` 헤더를 통해 경유한 캐시 서버를 명시합니다.
    - 이후 데이터의 변경을 확인하기 위해 `If-Modified-Since` 헤더를 추가합니다.
- 위에서 말한 모든 방식은 **리버스 프록시 구조**를 활용합니다. 원래 프록시라는 단어는 대리자라는 뜻을 갖고 있습니다. 클라이언트에서 발송되는 요청들을 프록시가 대신 전달해주는 **포워드 프록시 구조**가 그 원조이죠.
    - 포워드 프록시 구조 : A, B, C Client → Forward Proxy → A Server
    - 리버스 프록시 구조: A Client → Reverse Proxy → A, B, C Server
    - 프록시 구조는 클라이언트 ↔ 서버 구조에서 순서를 기준으로 숨겨지는 쪽이 앞쪽(포워드, 클라이언트)인지 뒷쪽(리버스, 서버)인지에 따라서 명칭이 달라집니다.
- 두 가지 프록시 구조는 각각의 단점이 존재하는데, 이를 해결하는 방법 중 하나가 **트랜스페어런트 프록시**입니다.
    - 이 프록시는 클라이언트에 프록시로 요청을 전송하기 위한 사전 조치도, DNS에 서버의 주소를 등록하는 방법도 필요하지 않습니다. 단지 캐시 서버에서 패킷 헤더를 조사해 전송 대상을 판단합니다.
    - 대신 브라우저에서 웹 서버로 리퀘스트 **메시지가 흘러가는 통로에 프록시를 설치**합니다.
        - 그리고 이 프록시를 통과할 때 패킷을 가로채 전송될 웹 서버를 지정합니다.
        - 이를 통하게 되면 브라우저에선 프록시에 대한 캡슐화가 가능합니다.
        - 하지만 이 방법은 리퀘스트 메시지가 흘러갈 수 있는 길의 수가 프록시 수와 비례하기 때문에 한 통로를 통해 메시지가 흘러나가도록 네트워크 구조를 설계합니다.
        - 인터넷에 연결하는 액세스 회선이 위 형태를 띄기 때문에 액세스 회선 부분에 설치도 가능합니다.조로 되어있습니다.

---

### 5. 콘텐츠 배포 서비스

- 캐시 서버는 클라이언트와 서버 중 어느 쪽에 두느냐에 따라 트래픽의 크기와 이용 효율에 차이가 존재합니다.
    - 클라이언트 쪽에 존재하는 경우 트래픽을 억제할 수 있지만, 서버 운영자의 핸들링이 불가능합니다.
    - 반면 서버 측 캐시 서버는 핸들링이 가능하지만 트래픽 자체를 억제하진 못합니다.
    - 따라서 둘의 장점만을 따온 방법이 존재합니다. 바로 **프로바이더(ISP)와의 계약을 통해 서버 운영자가 핸들링 할 수 있는 캐시 서버를 클라이언트 측 프로바이더에 설치**하는 방법입니다.
- 위 방법은 프로바이더와의 계약을 필요로 하기 때문에 상당한 비용을 유발합니다. 따라서 이를 대신해주는 서비스가 등장했는데 이를 **콘텐츠 배포 서비스(Content Delivery Service)**라고 부르며, 이를 제공하는 사업자는 **CDSP(Content Delivery Service Provider)**라고 부릅니다.
- CDS를 이용할 때 단순히 DNS 서버에 서버 주소를 입력하는 방식으로는 먼 거리의 서버에 요청을 보내는 비효율이 발생할 수 있습니다.
    - 이를 방지하기 위해 캐시 서버를 설치한 장소의 라우터로부터 경로 정보를 수집하고 이를 통해 클라이언트와의 거리를 계산합니다.
    - HTTP 헤더의 `Location` 필드를 사용하는 다른 방법도 존재합니다. 헤더 필드를 통해 어떤 웹 서버로 액세스할 지 명시해줍니다.